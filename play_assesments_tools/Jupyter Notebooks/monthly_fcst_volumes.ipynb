{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from config.config_loader import get_config\n",
    "import AnalyticsAndDBScripts.sql_connect as sql\n",
    "import AnalyticsAndDBScripts.prod_fcst_functions as fcst\n",
    "import AnalyticsAndDBScripts.sql_schemas as schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs\n",
    "sql_creds_dict = get_config('credentials', 'sql1_sa')\n",
    "\n",
    "# Add database name to the dictionary\n",
    "sql_creds_dict['db_name'] = 'Analytics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query statement\n",
    "statement = '''\n",
    "SELECT TOP 10 * FROM dbo.vw_FORECAST\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute query and store results in a dataframe\n",
    "engine = sql.sql_connect(\n",
    "    username=sql_creds_dict['username'], \n",
    "    password=sql_creds_dict['password'], \n",
    "    db_name=sql_creds_dict['db_name'], \n",
    "    server_name=sql_creds_dict['servername'], \n",
    "    port=sql_creds_dict['port']\n",
    ")\n",
    "try:\n",
    "    fcst_df = pd.read_sql(statement, engine)\n",
    "finally:\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values with 0 in fcst_df\n",
    "fill_cols = ['Q1', 'Q2', 'Q3', 'Qabn', 'Dei', 'b_factor', 'Def', 't1', 't2']\n",
    "fcst_df[fill_cols] = fcst_df[fill_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_arps(row, duration):\n",
    "    '''\n",
    "    Apply arps_segments function to each row of a dataframe.\n",
    "    :param row: A row from a dataframe\n",
    "    '''\n",
    "    # Dictionary for mapping PHASE_INT to a measure\n",
    "    reverse_phase_dict = {1: 'OIL', 2: 'GAS', 3: 'WATER'}\n",
    "    \n",
    "    # Ensure StartMonth < duration\n",
    "    if (row['StartMonth'] >= duration) | (row['Q3'] <= row['Qabn']):\n",
    "        # Create a DataFrame with a single row of default values\n",
    "        data = {\n",
    "            'WellID': [row['WellID']],\n",
    "            'Measure': [reverse_phase_dict.get(row['PHASE_INT'], 'UNKNOWN')],\n",
    "            'ProdMonth': [row['StartMonth']],\n",
    "            'ProductionRate': [None],\n",
    "            'De': [None],\n",
    "            'CumulativeProduction': [row['StartCumulative']],\n",
    "            'MonthlyVolume': [None],\n",
    "            'ForecastID': [row['ForecastID']],\n",
    "            'StartDate': [row['StartDate']],\n",
    "            'StartMonth': [row['StartMonth']]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        # Otherwise, apply arps_segments function\n",
    "        arr = fcst.arps_segments(\n",
    "            row['WellID'], \n",
    "            row['PHASE_INT'],\n",
    "            row['Q1'], \n",
    "            row['Q2'], \n",
    "            row['Q3'], \n",
    "            row['Dei'], \n",
    "            row['Def'], \n",
    "            round(row['b_factor'], 4), \n",
    "            row['Qabn'],\n",
    "            row['t1'],\n",
    "            row['t2'],\n",
    "            duration,\n",
    "            row['StartCumulative'],\n",
    "            row['StartMonth']\n",
    "        )\n",
    "        df = pd.DataFrame(np.stack(arr).T, columns=['WellID', 'Measure', 'ProdMonth', 'ProductionRate', 'De', 'CumulativeProduction', 'MonthlyVolume'])\n",
    "        df = df.dropna(subset=['ProdMonth'])\n",
    "        df['Measure'] = df['Measure'].map(reverse_phase_dict)\n",
    "    df['ForecastID'] = row['ForecastID']\n",
    "    df['StartDate'] = row['StartDate']\n",
    "    df['StartMonth'] = row['StartMonth']\n",
    "    df[['WellID', 'ProdMonth', 'StartMonth']] = df[['WellID', 'ProdMonth', 'StartMonth']].astype('int64')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set forecast duration in months\n",
    "duration = 360\n",
    "\n",
    "# Apply arps_segments function to each row of the dataframe\n",
    "monthly_df = pd.concat([apply_arps(row, duration) for _, row in fcst_df.iterrows()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify monthly_df to add a column to help calculate a Date column in SQL and resort columns\n",
    "monthly_df['AdjustedMonth'] = monthly_df['ProdMonth'] - monthly_df['StartMonth']\n",
    "col_order = ['ForecastID', 'WellID', 'Measure', 'ProdMonth', 'ProductionRate', 'De', 'CumulativeProduction', 'MonthlyVolume']\n",
    "monthly_df = monthly_df[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NaN to None for proper database insertion\n",
    "monthly_df = monthly_df.where(pd.notnull(monthly_df), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataframe into chunks of 500000 rows\n",
    "def split_dataframe(df, chunk_size):\n",
    "    return [df.iloc[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "chunk_size = 500000\n",
    "dataframes_list = split_dataframe(monthly_df, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load well_df into dbo.FORECAST_VOLUME_STAGE table in SQL Server\n",
    "for df_chunk in dataframes_list:\n",
    "    sql.load_data_to_sql(df_chunk, sql_creds_dict, schema.forecast_volume_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data from dbo.FORECAST_STAGE to dbo.FORECAST_VOLUME and drop dbo.FORECAST_VOLUME_STAGE\n",
    "sql.execute_stored_procedure(sql_creds_dict, 'sp_InsertFromStagingToForecastVolume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
