{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from config.config_loader import get_config\n",
    "import AnalyticsAndDBScripts.sql_connect as sql\n",
    "import AnalyticsAndDBScripts.sql_schemas as schema\n",
    "import AnalyticsAndDBScripts.well_spacing as ws\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import Lock, Manager\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from branca.element import Template, MacroElement\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials for SQL\n",
    "sql_creds_dict = get_config('credentials', 'sql1_sa')\n",
    "\n",
    "# Add db_name to the dictionary\n",
    "sql_creds_dict['db_name'] = 'Analytics'\n",
    "\n",
    "# Load parameters\n",
    "params = get_config('well_spacing')\n",
    "fit_groups_config = params['fit_groups']\n",
    "projection = params['final_projection']\n",
    "min_lat_length = params['minimum_lateral_length']\n",
    "update_date = pd.Timestamp.now()\n",
    "day_offset = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sql statements\n",
    "def create_statement(config, group_name, min_lat_length, day_offset=0):\n",
    "    # Function to extract basin list from config\n",
    "    def get_basins(config, group_name):\n",
    "        return next((group['Basins'] for group in config if group['name'] == group_name), None)\n",
    "\n",
    "    # Functions to create sql statements\n",
    "    def create_statement_inclusive(config, group_name, min_lat_length, day_offset):\n",
    "        basin_sql = \"', '\".join(get_basins(config, group_name))\n",
    "        return f'''\n",
    "        WITH MinUpdateDate AS (\n",
    "            SELECT      MIN(S.UpdateDate) AS MinDate\n",
    "            FROM        dbo.WELL_SPACING S\n",
    "            INNER JOIN  dbo.WELL_HEADER W ON S.WellID = W.WellID\n",
    "            WHERE       W.Trajectory = 'HORIZONTAL' \n",
    "            AND         W.FirstProdDate >= '2003-01-01' \n",
    "            AND         W.LateralLength_FT > {min_lat_length}\n",
    "            AND         W.Basin IN ('{basin_sql}')\n",
    "        ),\n",
    "        FilteredWells AS (\n",
    "            SELECT      W.WellID, W.API_UWI_Unformatted, W.Basin, W.FirstProdDate, W.LateralLength_FT, W.Geometry.STAsText() AS Geometry, \n",
    "                        W.Geometry.STSrid AS EPSGCode, W.Latitude, W.Longitude, W.Latitude_BH, W.Longitude_BH, U.MinDate\n",
    "            FROM        dbo.WELL_HEADER W\n",
    "            CROSS JOIN\tMinUpdateDate U\n",
    "            WHERE       W.Trajectory = 'HORIZONTAL' \n",
    "            AND         W.FirstProdDate >= '2003-01-01' \n",
    "            AND         W.LateralLength_FT > {min_lat_length}\n",
    "            AND         W.Geometry IS NOT NULL\n",
    "            AND         W.Basin IN ('{basin_sql}')\n",
    "        )\n",
    "        SELECT      * \n",
    "        FROM        FilteredWells\n",
    "        WHERE       MinDate IS NULL OR DATEADD(day, {day_offset}, MinDate) <= GETDATE()\n",
    "        '''\n",
    "\n",
    "    # Function to create SQL statement for basins not in any group\n",
    "    def create_statement_exclusive(config, min_lat_length, day_offset):\n",
    "        all_basins = [basin for group in config for basin in group['Basins']]\n",
    "        all_basins_sql = \"', '\".join(all_basins)\n",
    "        return f'''\n",
    "        WITH MinUpdateDate AS (\n",
    "            SELECT      MIN(S.UpdateDate) AS MinDate\n",
    "            FROM        dbo.WELL_SPACING S\n",
    "            LEFT JOIN   dbo.WELL_HEADER W ON S.WellID = W.WellID\n",
    "            WHERE       W.Trajectory = 'HORIZONTAL' \n",
    "            AND         W.FirstProdDate >= '2003-01-01' \n",
    "            AND         W.LateralLength_FT > {min_lat_length}\n",
    "            AND         (W.Basin NOT IN ('{all_basins_sql}') OR W.Basin IS NULL)\n",
    "        ),\n",
    "        FilteredWells AS (\n",
    "            SELECT      W.WellID, W.API_UWI_Unformatted, W.Basin, W.FirstProdDate, W.LateralLength_FT, W.Geometry.STAsText() AS Geometry, \n",
    "                        W.Geometry.STSrid AS EPSGCode, W.Latitude, W.Longitude, W.Latitude_BH, W.Longitude_BH, U.MinDate\n",
    "            FROM        dbo.WELL_HEADER W\n",
    "            CROSS JOIN\tMinUpdateDate U\n",
    "            WHERE       W.Trajectory = 'HORIZONTAL' \n",
    "            AND         W.FirstProdDate >= '2003-01-01' \n",
    "            AND         W.LateralLength_FT > {min_lat_length}\n",
    "            AND         W.Geometry IS NOT NULL\n",
    "            AND         (W.Basin NOT IN ('{all_basins_sql}') OR W.Basin IS NULL)\n",
    "        )\n",
    "        SELECT      * \n",
    "        FROM        FilteredWells\n",
    "        WHERE       MinDate IS NULL OR DATEADD(day, {day_offset}, MinDate) <= GETDATE()\n",
    "        '''\n",
    "    \n",
    "    if group_name == 'OTHER':\n",
    "        return create_statement_exclusive(config, min_lat_length, day_offset)\n",
    "    else:\n",
    "        return create_statement_inclusive(config, group_name, min_lat_length, day_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute query and store results in a dataframe\n",
    "def load_data(creds, statement):\n",
    "    engine = sql.sql_connect(\n",
    "        username=creds['username'], \n",
    "        password=creds['password'], \n",
    "        db_name=creds['db_name'], \n",
    "        server_name=creds['servername'], \n",
    "        port=creds['port']\n",
    "    )\n",
    "    try:\n",
    "        df = pd.read_sql(statement, engine)\n",
    "    finally:\n",
    "        engine.dispose()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each basin\n",
    "def process_data(args):\n",
    "    config, group_name, projection, min_lat_length, day_offset, update_date, sql_creds_dict, lock = args\n",
    "    try:\n",
    "        # Load data from SQL Server\n",
    "        statement = create_statement(config, group_name, min_lat_length, day_offset)\n",
    "\n",
    "        df = load_data(sql_creds_dict, statement)\n",
    "\n",
    "        if df.empty:\n",
    "            print(f\"No data for fit_group {group_name}\")\n",
    "            return\n",
    "    \n",
    "        # Apply optimize_buffer function to dataframe\n",
    "        df = ws.optimize_buffer(df, geo_col='Geometry', sfc_lat_col='Latitude', sfc_long_col='Longitude', buffer_distance_ft=params['buffer_distance'])\n",
    "\n",
    "        # Clean dataframe and prep for distance calculations\n",
    "        df = ws.prep_df_distance(df, well_id_col='WellID')\n",
    "\n",
    "        # Apply calculations to the dataframe\n",
    "        df_cols = ['MinDistance', 'MedianDistance', 'MaxDistance', 'AvgDistance', 'neighbor_IntersectionFraction', 'RelativePosition']\n",
    "        df[df_cols] = df.apply(ws.calculate_distance, axis=1, result_type='expand')\n",
    "\n",
    "        # Columns that contain spatial data\n",
    "        geometry_columns = ['clipped_lateral_geometry', 'lateral_geometry_buffer', 'clipped_neighbor_lateral_geometry', 'neighbor_lateral_geometry_buffer']\n",
    "\n",
    "        # Reproject geometries from EPSG:6579 to defined projection\n",
    "        for col in geometry_columns:\n",
    "            gdf = gpd.GeoDataFrame(df, geometry=col, crs='EPSG:6579')\n",
    "            gdf = gdf.to_crs(projection)\n",
    "            df[col] = gdf.geometry\n",
    "\n",
    "        # Add a few columns to the dataframe\n",
    "        df['Projection'] = projection\n",
    "        df['UpdateDate'] = update_date\n",
    "\n",
    "        # Drop rows with null values\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Divide dataframes into chunks\n",
    "        def split_dataframe(df, chunk_size):\n",
    "            return [df.iloc[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "        clean_df_list = split_dataframe(df, 500000)\n",
    "        \n",
    "        # Manage memory\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "        # Convert geometry columns to text\n",
    "        for df in clean_df_list:\n",
    "            df = df.map(ws.geom_to_wkt)\n",
    "            sql.load_data_to_sql(df, sql_creds_dict, schema.well_spacing_stage, lock)\n",
    "            del df\n",
    "            gc.collect()\n",
    "\n",
    "        # Manage memory\n",
    "        del clean_df_list\n",
    "        gc.collect()\n",
    "\n",
    "        # Move data from dbo.WELL_SPACING_STAGE to dbo.WELL_SPACING and drop dbo.WELL_SPACING_STAGE\n",
    "        sql.execute_stored_procedure(sql_creds_dict, 'sp_InsertFromStagingToWellSpacing', lock)\n",
    "\n",
    "        print(f\"Processing fit_group {group_name} complete\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing fit_group {group_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table WELL_SPACING_STAGE\n",
      "Data loaded into table WELL_SPACING_STAGE\n",
      "Stored procedure sp_InsertFromStagingToWellSpacing executed successfully.\n",
      "Processing fit_group WILLISTON complete\n"
     ]
    }
   ],
   "source": [
    "# Calculate well spacing calcuations and load data into Axia_Anaytics\n",
    "def main():\n",
    "    fit_group_list = ['WILLISTON'] # [group['name'] for group in fit_groups_config] + ['OTHER']\n",
    "\n",
    "    with Manager() as manager:\n",
    "        lock = manager.Lock()\n",
    "        args_list = [(fit_groups_config, group, projection, min_lat_length, day_offset, update_date, sql_creds_dict, lock) for group in fit_group_list]\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            futures = [executor.submit(process_data, args) for args in args_list]\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                try:\n",
    "                    future.result()  # Get the result to catch any exceptions\n",
    "                except Exception as exc:\n",
    "                    print(f'Generated an exception: {exc}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the clipped well survey, surface location, and the buffer around the well survey\n",
    "def plot_rows(gdf, start_row, end_row):\n",
    "    for row in range(start_row, end_row + 1):\n",
    "        fig, ax = plt.subplots()\n",
    "        current_row = gdf.iloc[[row]]\n",
    "\n",
    "        # Plot the surface location\n",
    "        current_row.set_geometry('sfc_loc').plot(ax=ax, color='blue', marker='o', markersize=50)\n",
    "\n",
    "        # Plot the LateralLine\n",
    "        current_row.set_geometry('clipped_lateral_geometry').plot(ax=ax, color='red')\n",
    "\n",
    "        # Plot the buffer (add this line)\n",
    "        current_row.set_geometry('lateral_geometry_buffer').plot(ax=ax, color='green', alpha=0.5)\n",
    "\n",
    "        # Show rectangle conformity\n",
    "        conformity = current_row['optimal_conformity'].values[0]\n",
    "        optimal_buffer = current_row['optimal_buffer'].values[0]\n",
    "        ax.set_title(f\"Rectangle Conformity: {conformity:.2f}, Optimal Buffer: {optimal_buffer}\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHOW_PLOTS = False\n",
    "basin = 'SAN JUAN'\n",
    "if SHOW_PLOTS:\n",
    "    # Plot the clipped well survey, surface location, and the buffer around the well survey\n",
    "    new_df = ws.optimize_buffer(df[df['Basin'] == basin], geo_col='Geometry', sfc_lat_col='Latitude', sfc_long_col='Longitude', buffer_distance_ft=params['buffer_distance'])\n",
    "    plot_rows(new_df, start_row=0, end_row=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a map of all of the LateralLine and clipped_LateralLine geometries\n",
    "SHOW_FOLIUM_MAP = SHOW_PLOTS\n",
    "SHOW_BUFFER = False\n",
    "if SHOW_PLOTS & SHOW_FOLIUM_MAP:\n",
    "    # Convert WKT to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(new_df, geometry='Geometry', crs=\"EPSG:6579\")\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "    gdf = gdf.dropna(subset=['Geometry'])\n",
    "\n",
    "    clipped_gdf = gpd.GeoDataFrame(new_df, geometry='clipped_lateral_geometry', crs=\"EPSG:6579\")\n",
    "    clipped_gdf = clipped_gdf.to_crs(\"EPSG:4326\")\n",
    "    clipped_gdf = clipped_gdf.dropna(subset=['clipped_lateral_geometry'])\n",
    "\n",
    "    buffer_gdf = gpd.GeoDataFrame(new_df, geometry='lateral_geometry_buffer', crs=\"EPSG:6579\")\n",
    "    buffer_gdf = buffer_gdf.to_crs(\"EPSG:4326\")\n",
    "    buffer_gdf = buffer_gdf.dropna(subset=['lateral_geometry_buffer'])\n",
    "\n",
    "    # Create a Folium map\n",
    "    m = folium.Map(location=[34.846, -96.111], zoom_start=10, tiles='OpenStreetMap')\n",
    "\n",
    "    # Add LateralLine geometries to the map\n",
    "    for idx, row in gdf.iterrows():\n",
    "        color = 'blue'\n",
    "        folium.GeoJson(\n",
    "            row['Geometry'],\n",
    "            style_function=lambda x, color=color: {'color': color},\n",
    "            tooltip=f\"WellID: {row['WellID']}\"\n",
    "        ).add_to(m)\n",
    "    # Add clipped_LateralLine geometries to the map\n",
    "    for idx, row in clipped_gdf.iterrows():\n",
    "        color = 'red'\n",
    "        folium.GeoJson(\n",
    "            row['clipped_lateral_geometry'],\n",
    "            style_function=lambda x, color=color: {'color': color},\n",
    "            tooltip=f\"Clipped Distance: {row['optimal_buffer']:.0f}\"\n",
    "        ).add_to(m)\n",
    "    if SHOW_BUFFER:\n",
    "        # Add optimal_buffer geometries to the map\n",
    "        for idx, row in buffer_gdf.iterrows():\n",
    "            color = 'green'\n",
    "            folium.GeoJson(\n",
    "                row['lateral_geometry_buffer'],\n",
    "                style_function=lambda x, color=color: {'color': color},\n",
    "                tooltip=f\"Rectangular Conformity: {row['optimal_conformity']:.3f}\"\n",
    "            ).add_to(m)\n",
    "\n",
    "    # Add WMS layer\n",
    "    wms = folium.WmsTileLayer(\n",
    "        url='https://gis.blm.gov/arcgis/services/Cadastral/BLM_Natl_PLSS_CadNSDI/MapServer/WmsServer?',\n",
    "        layers=[1, 2, 3],\n",
    "        fmt='image/png',\n",
    "        transparent=True,\n",
    "        version='1.3.0'\n",
    "    )\n",
    "\n",
    "    wms.add_to(m)\n",
    "\n",
    "    # Add legend to the map\n",
    "    legend_html = '''\n",
    "    {% macro html(this, kwargs) %}\n",
    "    <div style=\"position: fixed; bottom: 50px; left: 50px; z-index:9999; background-color: white; border:2px solid grey; border-radius:6px; padding: 10px;\">\n",
    "        <p><strong>Legend</strong></p>\n",
    "        <p><span style=\"color:blue;\">●</span> LEFT</p>\n",
    "        <p><span style=\"color:red;\">●</span> RIGHT</p>\n",
    "        <p><span style=\"color:grey;\">●</span> OTHER</p>\n",
    "    </div>\n",
    "    {% endmacro %}\n",
    "    '''\n",
    "    legend = MacroElement()\n",
    "    legend._template = Template(legend_html)\n",
    "    m.get_root().add_child(legend)\n",
    "    m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
